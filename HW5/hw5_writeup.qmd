---
title: "Homework 5"
author: "Kelsey Hawkins"
format: pdf
---

# Introduction
Generative models have gained popularity in the past few years in the utilization of Generative AI, however they have been around for longer than most realize. With the implication and use of sampling gaussian distributions as well as employing the idea of probabilities and latent spaces, generative models become possible. Simpler generative models include Naive Bayes, and Gaussian Mixture Models. More complex generative models include Generative Adversarial Networks (GAN), Variational Autoencoders (VAE), and GPT models as used in Chat-GPT. In this report, three different models will be compared in their training, model building, and output abilities to understand the differences between VAE, GAN, and C-GAN. 


# Differences Between Model Architechtures, Inputs/Outputs, Loss(es) and Training
**Variational Auto Encoder** -> This first model consists of an encoder and decoder, taking in flattened and transposed images, then utilizing Adam optimizer, then KL_loss and reconstruction loss during training. 
The encoder in this model consists of an encoder with eight layers with the purpose of the output being a sample from a distribution. There is the input layer which takes in a 28x28x1 image, two convolutional layers with relu activation, a stride of two and "same" padding for size reduction while the output of the first layer is smaller than the second layer. The next layer is a flatten layer then two dense layers. The first dense layer is a standard rely activation function and the second dense layer has a latent dimension of two. This is fed into a custom sampling function that takes in the mean and variation of the previous output to sample from that gaussian distribution, in a two-dimensional space. The output is in the side of the latent dimension of two. 
The decoder in this model consists of six layers, with the purpose of taking the encoders output and performing transpose convolutions to generate an image from the sampled probablistic space. The layers consists of an input layer, then a reshaping layer to ensure the dimensions of the channels is as expected with a 7x7x64 shape. This is then used in the converse transposed layers which then feed into the output. The output shape has a size of one as there is only one output with three channels.
The model training is done with a custom training step that employs reconstruction loss, and KL loss. The MNIST dataset is first regularized into values beween 0 and 1, then fed into the model. It is compiled with teh Adam optimizer and fit for 30 epochs with a batch size of 128. 

**Generative Adversarial Network** -> 

**Conditional Generative Adversarial Network** -> 


Explain **in detail** the difference between how we generate samples in the 3 models (e.g. what are the differences in the inputs of each model, how they're trained, the types of layers, activations, sizes, the way they generate samples, their loss functions,...etc).


# Comparison of Outputs (e.g. quality, ease of getting new samples, interpolation/smoothness)

Your subjective opinions on the differences in the generated images (e.g. quality, blurriness, realism, ability to interpolate, ease of selecting a particular digit...etc).


![My Caption Here](/Users/cparlett/Desktop/corgi.jpg){width=300}

(Note that the `width=300` argument controls how wide your image will be.)

# Generated images

Put all your generated images here:
![My Caption Here](/Users/cparlett/Desktop/corgi.jpg){width=300}