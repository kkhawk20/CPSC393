{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Homework 2\"\n",
        "author: \"Kelsey Hawkins\"\n",
        "format: pdf\n",
        "---"
      ],
      "id": "ad429013"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction\n",
        "ASL is a prominent language in the American deaf community. With this in mind, I have a dataset of images containing the ASL dictionary, excluding the letters that need motion. The dataset was already flattened into greyscale values, ready for model input with a few preprocessing changes. This model will help translate ASL images to text for those who do not understand it, or want to learn it. \n",
        "\n",
        "# Analysis \n",
        "Any exploratory analysis of your data, and general summarization of the data (e.g. summary statistics, correlation heatmaps, graphs, information about the data...). Tell the reader about the types of variables you have and some general information about them, Plots and/or Tables are always great. This should also include any cleaning and joining you did.\n"
      ],
      "id": "28c4606d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Random Images from dataset\n",
        "#| fig-cap: Random Images from Dataset\n",
        "#| echo: false\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import yaml\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.datasets import mnist\n",
        "import keras as kb\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "from plotnine import *\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
        "\n",
        "train_df = pd.read_csv(\"/Users/kelseyhawkins/Desktop/CPSC_Courses/CPSC_393/sign_mnist_train.csv\")\n",
        "test_df = pd.read_csv(\"/Users/kelseyhawkins/Desktop/CPSC_Courses/CPSC_393/sign_mnist_test.csv\")\n",
        "\n",
        "# Separating X and Y\n",
        "y_train = train_df['label']\n",
        "y_test = test_df['label']\n",
        "\n",
        "del train_df['label']\n",
        "del test_df['label']\n",
        "\n",
        "# rescale data to be 0-1 instead of 0-255\n",
        "trainX = train_df.astype(\"float32\") / 255.0\n",
        "testX = test_df.astype(\"float32\") / 255.0\n",
        "\n",
        "# change the labels to be in the correct format\n",
        "lb = LabelBinarizer()\n",
        "trainY = lb.fit_transform(y_train)\n",
        "testY = lb.transform(y_test)\n",
        "\n",
        "trainX.head()\n",
        "trainX.shape\n",
        "\n",
        "print(trainX.shape,\n",
        "trainY.shape)\n",
        "\n",
        "print(testX.shape,\n",
        "testY.shape)\n",
        "\n",
        "# Visualize some images!!!\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# I used different names cuz i wanted to reshape them without\n",
        "# Changing the original data put into the model :)\n",
        "x_train = train_df.values\n",
        "x_test = test_df.values\n",
        "x_train_vis = x_train.reshape(-1,28,28,1)\n",
        "x_test = x_test.reshape(-1,28,28,1)\n",
        "f, ax = plt.subplots(2,5)\n",
        "f.set_size_inches(10, 10)\n",
        "k = 0\n",
        "for i in range(2):\n",
        "    for j in range(5):\n",
        "        ax[i,j].imshow(x_train_vis[k].reshape(28, 28) , cmap = \"gray\")\n",
        "        k += 1\n",
        "    #plt.tight_layout()    \n"
      ],
      "id": "Random-Images-from-dataset",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Methods\n",
        "Explain the structure of your model and your approach to building it. This can also include changes you made to your model in the process of building it. Someone should be able to read your methods section and generally be able to tell exactly what architechture you used. However REMEMBER that this should be geared towards an audience who might not understand Keras code.\n",
        "\n",
        "# Results\n",
        "Detailed discussion of how your model performed. Include a discussion about whether or not Deep Learning was necessary in this situation.\n",
        "\n",
        "# Reflection\n",
        "In this assignment, I did not come across any struggles or problems with the code or analysis. However I did refer back to the math of the models to justify my answers and think about why the models performed the way they did. It was interesting to be able to quantify them with a simple classification problem and think about how each model handles class imbalances in the slightest way, by about 20%. In the future, I would approach it the same way as I did here, as it seemed to work well. \n"
      ],
      "id": "1603d6dc"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}